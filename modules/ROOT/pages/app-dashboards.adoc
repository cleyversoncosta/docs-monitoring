= Built-in Application Dashboard
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

Built-in dashboards display deployment information about your application at the top of the screen and provide access to a number of different graphs, for example:

image::dashboard-built-in-info.png[Deployment Info on an App in a Built-In Dashboard]

The graphs and tables in built-in dashboards support a number of metrics, including application metrics. The *Overview* tab provides overall measures. You can view more granular application metrics through the *Inbound*, *Outbound*, and *Failure* tabs.

Example use cases for monitoring are end-to-end tracing of API calls and dependency analyses to help you isolate the source of issues. For example, you can track response times at each endpoint (outbound or inbound).

.Example: Average Response Time Grouped by Endpoint Outbound
image::dashboard-outbound-response-table.png[Average Response Time Grouped By Endpoint Outbound]

* Infrastructure-level and JVM metrics
* Performance metrics that break down inbound and outbound response times into averages and percentiles

== View a Built-in Dashboard

Built-in and custom dashboards are available from Anypoint Monitoring. You can view application metrics for applications deployed to CloudHub and to hybrid targets in both built-in and custom dashboards.

. Sign into Anypoint Platform and click *Monitoring*.
. Select the *Environment* and *Resource name* for the app or API to view the corresponding dashboard.
. Click *View*. +
The built-in dashboard for the application or API is displayed.
. To switch to a dashboard for a different resource, click the built-in dashboard selector at the top of the page.
+
image::builtin-dashboard-selection-interaction.png[Built-in Dashboard Selector]

Your data is prepopulated and displayed in the built-in dashboards and logs; no configuration is needed.

Built-in dashboards include various pages to view different types of charts:

[%header,cols="1,4"]
|===
| Built-In Dashboards | Charts
| *Overview* a|

* Inbound - Total Requests by Response Type
* Inbound - Average Response Time
* Inbound - Mule messages
* Outbound - Total Requests by Response Type
* Outbound - Average Response Time
* JVM - CPU utilization
* JVM - Heap memory utilization
* JVM - Thread count

//* Response Time by App: Number of milliseconds (ms) required for each response.
//* Messages Processed: Number of messages at a given time.
//* Response Time by Inbound Endpoint: Number of milliseconds (ms) for a response from inbound endpoints to your Mule app.
//* Response Time by Outbound Endpoint: Number of milliseconds (ms) for a response from outbound endpoints of your Mule app.
//* CPU: Percentage of CPU used over time. The percentages are calculated per worker and as the total for all workers.
//* Memory: Number of mebibytes (MiB) used over time.
| *Inbound* a|

* Total Inbound Requests by Response Type
* Average Response Time
* Average Response Time by Endpoint
** Average: Green if response time is less than 300ms; yellow if response time is greater than 300ms and less than 600ms; red if is greater than 600ms
** Max: Green if response time is less than 300ms; yellow if response time is greater than 300ms and less than 500ms; red if is greater than 500ms
** Min: Green if response time is less than 300ms; yellow if response time is greater than 300ms and less than 600ms; red if is greater than 600ms
* Total Requests by Endpoint
* Response Time graphs (99, 90, 75, and 50 percentile inbound): Measured in milliseconds (ms)
* Maximum Response Time
* Total Failed Inbound Requests
* Slow Request Count by Endpoint: Total calls in which the response time is greater than 1000 ms

// I don't see Maximum Response Time or Total Failed Inbound Requests in the UI - do those exist?

The following charts are available only if you are using Unified Agent and have a Titanium subscription to Anypoint Platform:

* Inbound Protocol
* Inbound Endpoint

[NOTE]
Inbound metrics are retained for 24 hours.

//* Total Inbound Calls (success or failure)
//* Total Inbound by Endpoint Outbound
//* Average Response Time inbound
| *Outbound* a|

* Total Outbound Requests by Response Type
* Average Response Time
* Average Response Time grouped by HTTP endpoint outbound (only HTTP endpoints are shown)
* Total Requests grouped by HTTP endpoint (only HTTP endpoints are shown)
* Response Time graphs (99, 90, 75, and 50 percentile outbound): Measured in milliseconds (ms)
* Total Failed Outbound Requests

The following charts are available only if you are using Unified Agent and have a Titanium subscription to Anypoint Platform:

* Outbound Ports
* Outbound Operations
* Outbound Protocol
* Outbound Endpoints
| *Flows* a|

* Inbound Response Time by Flow: Average inbound response time
* Outbound Response Time by Flow: Average outbound response time
* Inbound Request Volume by Flow: Average number of inbound requests
* Outbound Request Volume by Flow: Average number of outbound requests
* Failures by Flow: Average number of failed inbound requests
* Slow Inbound Requests by Flow: Average number of inbound requests whose response time is greater than 1000 ms
* Slow Outbound Requests by Flow: Average number of outbound requests whose response time is greater than 1000 ms
* Inbound Response Time by Flow: Average, minimum, and maximum inbound response time
* Outbound Response Time by Flow: Average, minimum, and maximum outbound response time
* Inbound Request Volume by Flow: Average number of inbound requests
* Outbound Request Volume by Flow: Average number of outbound requests
* Failures by Flow: Average number of inbound failed requests
* Slow Inbound Requests by Flow: Average number of inbound requests whose response time is greater than 1000 ms
* Slow Outbound Requests by Flow: Average number of outbound requests whose response time is greater than 1000 ms

If you don't see the *Flows* tab, verify that you are using Unified Agent and have a Titanium subscription to Anypoint Platform.
| *Connectors* a|

* Connector Message Volume: Number of outbound messages and number of outbound requests
* Response Time by Connector: Average outbound response time

If you don't see the *Connectors* tab, verify that you have a Titanium subscription to Anypoint Platform and that the app you selected is a hybrid app deployed to a server, server group, or cluster. See xref:monitor-connectors.adoc[Monitor Connectors].
| *Performance* a|

* Average Response Time - Inbound
* Average Response Time Grouped by Endpoint - Inbound
* Mule Messages
* Response Time graphs: 99, 90, 75, and 50 percentile inbound
* Average Response Time  - Outbound
* Average Response Time Grouped by Endpoint - Outbound
* Response Time graphs: 99, 90, 75, and 50 percentile - Outbound
//* Response Time graphs: 99, 90, 75, and 50 Percentile Inbound
//* Average Response Time: Outbound, Grouped by Endpoint Outbound
| *Failures* a|

* Total Failed Inbound Requests
* Total Failed Outbound Requests
* All Inbound Requests grouped by response type
* All Outbound Requests grouped by response type
* Failed Inbound Requests: Response time by endpoint
* Total Failed Inbound Requests grouped by endpoint
* Failed Outbound Requests: Response time by HTTP endpoint (only HTTP endpoints are shown)
* Total Failed Outbound Requests grouped by HTTP endpoint (only HTTP endpoints are shown)
| *JVM* a|

* Garbage collection count, Garbage collection time
* Par new collection count, Par new collection time
* Classes: Loaded, Loaded total, Unloaded
* Heap: Committed, Used
* Thread Count: Number of simultaneous requests
* JVM Uptime: Uptime of the JVM
* Par Eden graphs (Used, Max, Init, and Committed): Usage metrics for the Par Eden Space pool
* Par Survivor graphs (Used, Max, Init, and Committed): Usage metrics for the Par Eden Space pool
* Metaspace graphs (Used, Max, Init, Committed): Usage metrics for Java memory space
* Code Cache graphs (Used, Max, Init, Committed): Usage metrics for the Code Cache pool
* Compressed Class Space graphs (Used, Max, Init, Committed): Usage metrics for values of the metadata for compressed class pointers
* Committed Virtual Memory: Amount of virtual memory guaranteed to be available to the running process
| *Infrastructure* a|

* Application Process CPU Load: Amount of CPU load used by the JVM
* Application Process CPU Minutes: CPU time used by the process on which the JVM is running
* Operating System Swap Space: Amount of memory the system is swapping
* CPU Utilization %: Percentage of CPU used by each worker over time
* Memory Utilization: Amount of memory used by each worker over time
* Total System Processors: Number of system processors for workers available over time
* Total System Memory: Amount of system memory available for workers over time. +
If you have a Titanium subscription and the selected application is hybrid, this graph changes to *System Memory*.
* System Memory: This graph displays only if you have a Titanium subscription and the selected application is hybrid. This graph displays the total free system memory per worker.
* Thread Count - Server: Number of simultaneous requests for a worker over time

.Example: Infrastructure Dashboard
image::dashboard-built-in-infrastructure.png[Example: Infrastructure Dashboard]
| *Custom metrics* a|

The *Custom metrics* tab displays only if you have a Titanium subscription and select an app running on a supported version of Mule. See xref:anypoint-custom-metrics-connector.adoc[Anypoint Custom Metrics Connector].
|===

=== How Endpoint Use Metrics Are Gathered

The built-in dashboards for apps contain charts that show endpoint metrics. The charts sort the available endpoints in a menu. When you designate a time period for the data that appears in the charts, the results shown in the endpoint charts can include multiple grouping intervals because the data is processed in intervals of time.
As a result, a given table usually shows top occurring endpoints and, depending on the number of endpoints, a group called *Other* that shows an aggregation of endpoints that do not occur as often for that time period.The tables show approximate counts for the most commonly occurring endpoints when the *Other* grouping appears.

For example, when an endpoint occurs more often than other endpoints in one interval but occurs less often in another interval (thus sorting it into the *Other* group for that interval), the resulting table displays lower than actual values for that endpoint, since the metrics that do not appear are grouped into the *Other* group.

== See Also

* xref:dashboard-custom-config.adoc[Configuring Custom Dashboards and Charts]
* xref:reports.adoc[Reports]
* xref:save-builtin-dashboard-as-custom.adoc[Save a Built-in Dashboard as a Custom Dashboard]
